{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lehenbauer/colab/blob/main/k_co_compose_7_tiny_clipper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xiLpYRYZ5LH"
      },
      "source": [
        "\n",
        "\n",
        "# Co-compose with OpenAI Jukebox vol. 2\n",
        "\n",
        "**Usage:**\n",
        "\n",
        "All the cells in this notebook have detailed instructions. Please inspect the whole notebook before running for the first time, to understand the workflow.\n",
        "If Jukebox is unfamiliar, we recommend watching the video tutorials, links below.\n",
        "\n",
        "When you start a new project, fill in the details in the \"Project options\" form.\n",
        "Later if you resume the project, just fill in the project folder name (the working directory with the priming wav).\n",
        "\n",
        "When resuming, the only thing you need to run in every session is the setup. Then you can go straight to where you left off, either to continue the song or upsample it. \n",
        "\n",
        "**Features:** \n",
        "- All the checkpoints and data are saved automatically on Google Drive; you can always start from where you left.\n",
        "- ...makes compact branches of your progress\n",
        "- Has speedy upsampling (one hour per minute instead of ten hours per minute)\n",
        "- artists/genres list\n",
        "- Volume normalization steps make upsampled results sound much better\n",
        "\n",
        "**Restrictions of this notebook:**\n",
        "- Co-composing only (other notebooks do other things)\n",
        "- Seed file required\n",
        "- 5b_lyrics model only\n",
        "\n",
        "\n",
        "# Thanks\n",
        "- to the team at OpenAI for making Jukebox: Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.\n",
        "\n",
        "- SMarioMan and Zag, for inspiring the original version of this notebook.\n",
        "\n",
        "- MichaelsLab for the speed upsampling code.\n",
        "\n",
        "- Broccaloo, reedmayhew and Jimney Baltigor for wealth of technical info.  Jimney also for the volume normalization technique.\n",
        "\n",
        "- FX Junkie, for testing help and suggesting the rerun option.\n",
        "\n",
        "- Johannezz, for the co-compose notebook Authentic Texas started from\n",
        "\n",
        "# Tutorial videos\n",
        "[Watch at youtube](https://youtu.be/5wn3htQ:l4JA) (no longer there :-( ). The video explains the earlier version, but the workflow is the same.\n",
        "\n",
        "johannezz  ([deeplearn.art](https://deeplearn.art))\n",
        "\n",
        "-- *Authentic Texas*, tweaker of the co-compose notebook and author of a series of videos on using OpenAI Jukebox to co-compose music."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq8uLwZCn0BV"
      },
      "source": [
        "\n",
        "# **Setup**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK9qYnel_5mQ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Check the GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPdMgaH_BPGN",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BgzAP1eXOkY"
      },
      "source": [
        "\n",
        "\n",
        "Project Directory must always be given here. It is simply the folder (or a path to subfolder) on Google drive where the primer wav is located. This notebook will put everything it makes within the same folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5RpbJ9OXLqS",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Project Directory on Google Drive\n",
        "PROJECT_DIRECTORY = '' #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "\n",
        "project_dir_path = '/content/gdrive/MyDrive/' + PROJECT_DIRECTORY\n",
        "if not os.path.isdir(project_dir_path):\n",
        "  raise NotADirectoryError(f\"Directory '{project_dir_path}' not found, please fix and retry\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX2VEf7X9Qkw"
      },
      "source": [
        "**If you are opening earlier project and do not intend to change anything, skip this cell**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*Wav*: the name of the primer wav (seed) in the project directory. Do not include .wav file extension.\n",
        "\n",
        "*Lyrics File* the name of a file containing lyrics, in the project directory.  If you leave this blank or the file doesn't exist, and it makes lyrics, they will be gibberish lyrics\n",
        "\n",
        "*Artist*: Leave blank or [pick one from the list](https://raw.githubusercontent.com/deeplearn-art/jukebox/master/artist_genres.txt)\n",
        "\n",
        "*Genre*:  [pick 0 to 4 from the list](https://raw.githubusercontent.com/openai/jukebox/master/jukebox/data/ids/v2_genre_ids.txt) \n",
        "\n",
        "*Prompt length*: How many seconds do you want to hear your priming wav in the beginning?\n",
        "\n",
        "*Initial song length*: How many seconds do you want to generate on the initial run? Must be less than 23 seconds.  I recommend 4 seconds.\n",
        "\n",
        "*Total song length*: How many seconds do you plan the final song to last? Must be at least 25 seconds.\n",
        "\n",
        "*Sampling temperature*: Lower values lean towards being more predictable and consistent while higher ones yield more adventurous, diverse outputs.  Recommended range between 0.95 and 0.99.  Start with 0.96 or 0.97.\n",
        "\n",
        "*Note*: An optional note to be attached to the branches\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBYqHTb5snb9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Setup Your Project\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "import soundfile as sf\n",
        "\n",
        "WAV = '' #@param {type:\"string\"}\n",
        "LYRICS_FILE = '' #@param {type:\"string\"}\n",
        "ARTIST= '' #@param {type:\"string\"}\n",
        "GENRE = \"\" #@param {type:\"string\"}\n",
        "PROMPT_LENGTH =   10#@param {type:\"number\"}\n",
        "INITIAL_SONG_LENGTH =  4#@param {type:\"number\"}\n",
        "TOTAL_SONG_LENGTH =  60#@param {type:\"number\"}\n",
        "#LYRICS = \"\" #@param {type:\"string\"}\n",
        "sampling_temperature = 0.96 #@param {type:\"number\"}\n",
        "NOTE = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# read the lyrics from the lyrics file if there is one\n",
        "LYRICS = ''\n",
        "if LYRICS_FILE:\n",
        "  lyrics_file_path = project_dir_path + '/' + LYRICS_FILE\n",
        "  with open(lyrics_file_path, 'r') as file:\n",
        "    LYRICS = file.read()\n",
        "\n",
        "hops = [.5, .5, .125] \n",
        "\n",
        "tokens_list = [0,0,0]\n",
        "info = {}\n",
        "info['PROJECT_DIRECTORY'] = PROJECT_DIRECTORY\n",
        "info['WAV'] = WAV\n",
        "info['ARTIST']= ARTIST\n",
        "info['GENRE'] = GENRE\n",
        "info['PROMPT_LENGTH'] = PROMPT_LENGTH\n",
        "info['INITIAL_SONG_LENGTH'] = INITIAL_SONG_LENGTH\n",
        "info['TOTAL_SONG_LENGTH'] = TOTAL_SONG_LENGTH\n",
        "info['LYRICS'] = LYRICS\n",
        "info['NOTE'] = NOTE\n",
        "info['SONG_LENGTH'] = 0\n",
        "info['TOKENS'] = tokens_list\n",
        "project_dir = f'/content/gdrive/MyDrive/{PROJECT_DIRECTORY}'\n",
        "\n",
        "\n",
        "ckpt = f\"{project_dir}/zs-checkpoint.t\" \n",
        "b_ckpt = f\"{project_dir}/zs-checkpoint-b.t\" #auto backup for re-run\n",
        "f_info = f\"{project_dir}/info.json\"\n",
        "b_info = f\"{project_dir}/b_info.json\" #auto backup for re-run\n",
        "\n",
        "def read_info(f_path):  \n",
        "  with open(f_path, 'r') as data:\n",
        "    info = json.load(data)  \n",
        "  return info  \n",
        "\n",
        "def save_info(f_path):\n",
        "  with open(f_path, 'w') as f:\n",
        "    json.dump(info, f)\n",
        "    \n",
        "def print_fancy(txt):\n",
        "  print('\\x1b[0;35m' + txt + '\\x1b[0m')\n",
        "\n",
        "def get_tokens_list(zs):\n",
        "  # tokens_list is a list variable that tracks the start of the\n",
        "  # last generated new tokens inside zs. It is stored in\n",
        "  # the branch dir info.json, so we can upsample only the newly\n",
        "  # added tokens (see truncate_zs, below)\n",
        "  tokens_list = [0,0,0]\n",
        "  for i in range(hps.levels):\n",
        "    tokens_list[i] = zs[i].shape[1] \n",
        "  return tokens_list  \n",
        "\n",
        "def truncate_zs(zs):\n",
        "  for i in range(hps.levels):\n",
        "    zs[i] = zs[i][:,tokens_list[i]:]\n",
        "  return zs  \n",
        "\n",
        "def backup(zs, note):\n",
        "  # makes new branch\n",
        "  d = datetime.datetime.now()\n",
        "  date_str = d.strftime(\"%Y%m%d-%H%M\")\n",
        "  bak_dir = f'{hps.name}/backup-{date_str}-{note}'\n",
        "  info['PROJECT_DIRECTORY'] = bak_dir\n",
        "  info['NOTE'] = note\n",
        "  info[\"TOKENS\"] = tokens_list\n",
        "  #%mkdir \"{bak_dir}\"\n",
        "  Path(bak_dir).mkdir(parents=True, exist_ok=True)\n",
        "  #%cp \"{hps.name}\"/*.wav \"{bak_dir}\"\n",
        "  for i in range(hps.n_samples):\n",
        "    shutil.copy(f'{hps.name}/clip_{i}.wav', bak_dir)\n",
        "  t.save(zs, f'{bak_dir}/zs-checkpoint.t')\n",
        "  save_info(f'{bak_dir}/info.json')  \n",
        "  #reset info back to main branch\n",
        "  info['PROJECT_DIRECTORY'] = hps.name\n",
        "  info['NOTE'] = ''\n",
        "  info[\"TOKENS\"] = [0,0,0]\n",
        "  \n",
        "def write_audio(start):\n",
        "  for i in range(hps.n_samples):\n",
        "     sf.write(f'clip_{i}.wav', x[i][start*hps.sr:], hps.sr)\n",
        "\n",
        "def scale_sample(sample_raw, max_abs=0.891):\n",
        "    # do peak normalization to prevent clipping.\n",
        "    # the default max of 0.891 coresponds to -1 dB.\n",
        "    sample_max = numpy.abs(sample_raw).max()\n",
        "    scale = max_abs / sample_max\n",
        "    print(f'Scaling - sample_max: {sample_max:.2f}, scale: {scale:.2f}')\n",
        "    sample_scaled = sample_raw * scale\n",
        "    return sample_scaled\n",
        "\n",
        "if not Path(f_info).is_file():\n",
        "  # TODO experiment with changing info during composing\n",
        "  save_info(f_info)\n",
        "\n",
        "info = read_info(f_info)  \n",
        "INITIAL_SONG_LENGTH = int(info['INITIAL_SONG_LENGTH'])\n",
        "PROMPT_LENGTH = int(info['PROMPT_LENGTH'])\n",
        "TOTAL_SONG_LENGTH = int(info['TOTAL_SONG_LENGTH'])\n",
        "SONG_LENGTH = int(info['SONG_LENGTH'])\n",
        "song_length = SONG_LENGTH\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owOWWny_YSCh",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title  Cache Model Files in Google Drive and Copy to Colab (optional)\n",
        "#save_and_load_models_from_drive = False\n",
        "save_and_load_models_from_drive = True\n",
        "model = '5b_lyrics'\n",
        "\n",
        "#START GDRIVE MODEL LOADER\n",
        "\n",
        "AZURE_URL=\"https://openaipublic.azureedge.net\"\n",
        "VMCACHE = \"/root/.cache\"\n",
        "GCACHE=\"/content/gdrive/MyDrive\"\n",
        "\n",
        "if save_and_load_models_from_drive == True:\n",
        "  import os.path\n",
        "  #!apt install rsync\n",
        "  !mkdir -p {VMCACHE}/jukebox/models/1b_lyrics {VMCACHE}/jukebox/models/5b_lyrics  {VMCACHE}/jukebox/models/5b\n",
        "  !mkdir -p {GCACHE}/jukebox/models/5b_lyrics {GCACHE}/jukebox/models/5b {GCACHE}/jukebox/models/1b_lyrics\n",
        "\n",
        "def cache_load_file(pathFragment):\n",
        "    basename = os.path.basename(pathFragment)\n",
        "    if os.path.exists(f\"{VMCACHE}/{pathFragment}\") == False:\n",
        "      if os.path.exists(f\"{GCACHE}/{pathFragment}\") == False:\n",
        "        print(f\"{basename} not stored in Google Drive... downloading it.\")\n",
        "        !wget {AZURE_URL}/{pathFragment} -O {GCACHE}/{pathFragment}\n",
        "      else:\n",
        "        print(f\"{basename} found in Google Drive.\")\n",
        "      print(f'Copying {basename} from Google Drive to VM')\n",
        "      !rsync -a --progress {GCACHE}/{pathFragment} {VMCACHE}/{pathFragment}\n",
        "\n",
        "def load_5b_vqvae():\n",
        "    cache_load_file(\"jukebox/models/5b/vqvae.pth.tar\")\n",
        "\n",
        "def load_1b_lyrics_level2():\n",
        "    cache_load_file(\"jukebox/models/1b_lyrics/prior_level_2.pth.tar\")\n",
        "\n",
        "def load_5b_lyrics_level2():\n",
        "  cache_load_file(\"jukebox/models/5b_lyrics/prior_level_2.pth.tar\")\n",
        "\n",
        "def load_5b_level1():\n",
        "  cache_load_file('jukebox/models/5b/prior_level_1.pth.tar')\n",
        "\n",
        "def load_5b_level0():\n",
        "  cache_load_file('jukebox/models/5b/prior_level_0.pth.tar')\n",
        "\n",
        "def load_5b_level2():\n",
        "  cache_load_file('jukebox/models/5b/prior_level_2.pth.tar')\n",
        "\n",
        "if save_and_load_models_from_drive == True:\n",
        "  if model == '5b_lyrics':\n",
        "    load_5b_vqvae()\n",
        "    load_5b_lyrics_level2()\n",
        "    load_5b_level1()\n",
        "    load_5b_level0()\n",
        "  if model == '5b':\n",
        "    load_5b_vqvae()\n",
        "    load_5b_level2()\n",
        "    load_5b_level1()\n",
        "    load_5b_level0()\n",
        "  elif model == '1b_lyrics':\n",
        "    load_5b_vqvae()\n",
        "    load_1b_lyrics_level2()\n",
        "    load_5b_level1()\n",
        "    load_5b_level0()\n",
        "#END GDRIVE MODEL LOADER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3lvUGmapK0i"
      },
      "source": [
        "\n",
        "\n",
        " In general you can extend 2 up to 6 clips depending on the chip. \n",
        " \n",
        " If you get a T4 GPU, set the number of clips to 2 with the following slider. Set it to 6 if you're on \"premium\" GPU, i.e. A100.  You might go higher but it starts getting overwhelming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_BWO10IpFpC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title  Set the number of the clips\n",
        "number_of_clips = 6 #@param {type:\"slider\", min:1, max:6, step:1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNLX27fAnbAb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Setup and install Jukebox.\n",
        "\n",
        "!pip install git+https://github.com/deeplearn-art/jukebox-saveopt\n",
        "import torch as t\n",
        "import librosa\n",
        "import datetime\n",
        "from IPython.display import display, Audio\n",
        "\n",
        "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
        "from jukebox.hparams import Hyperparams, setup_hparams\n",
        "from jukebox.sample import sample_single_window, _sample, \\\n",
        "                           sample_partial_window, upsample, \\\n",
        "                           load_prompts\n",
        "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
        "from jukebox.utils.torch_utils import empty_cache\n",
        "#rank, local_rank, device = setup_dist_from_mpi()\n",
        "\n",
        "# MPI Connect. MPI doesn't like being initialized twice, hence the following\n",
        "try:\n",
        "    if device is not None:\n",
        "        pass\n",
        "except NameError:\n",
        "    rank, local_rank, device = setup_dist_from_mpi()\n",
        "\n",
        "model = \"5b_lyrics\" \n",
        "hps = Hyperparams()\n",
        "hps.sr = 44100\n",
        "hps.n_samples = number_of_clips\n",
        "hps.name = project_dir\n",
        "hps.hop_fraction = hops\n",
        "hps.levels = 3\n",
        "lower_batch_size = 16\n",
        "max_batch_size = 2\n",
        "lower_level_chunk_size =32 #512 #\n",
        "chunk_size = 16 #256 \n",
        "\n",
        "vqvae, *priors = MODELS[model]\n",
        "vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
        "top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)\n",
        "mode = 'primed'\n",
        "# find out if we have saved anything\n",
        "ckpt =  f'{hps.name}/zs-checkpoint.t'\n",
        "data = f\"{hps.name}/level_1/data.pth.tar\"\n",
        "data_0 = f\"{hps.name}/level_0/data.pth.tar\"\n",
        "zs = None    \n",
        "resume_state = \"\"\n",
        "if os.path.exists(hps.name):\n",
        "  if os.path.isfile(data_0):\n",
        "    mode = 'upsample'\n",
        "    codes_file = data_0\n",
        "    resume_state = \"upsampling\"\n",
        "    audio_file=None\n",
        "  if os.path.isfile(data):\n",
        "    mode = 'upsample'\n",
        "    codes_file = data\n",
        "    resume_state = \"upsampling\"\n",
        "    audio_file=None  \n",
        "  elif os.path.isfile(ckpt):\n",
        "    resume_state = \"composing\"  \n",
        "    \n",
        "if resume_state != 'upsampling': \n",
        "  codes_file=None\n",
        "  audio_file = f\"{project_dir}/{info['WAV']}.wav\"\n",
        "\n",
        "print(f\"mode : {mode}\")\n",
        "sample_hps = Hyperparams(dict(mode=mode, codes_file=codes_file, audio_file=audio_file, prompt_length_in_seconds=PROMPT_LENGTH))\n",
        "\n",
        "sample_length_in_seconds = TOTAL_SONG_LENGTH \n",
        "hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'\n",
        "\n",
        "metas = [dict(artist = info['ARTIST'],\n",
        "          genre = info['GENRE'],\n",
        "          total_length = hps.sample_length,\n",
        "          offset = 0,\n",
        "          lyrics = info['LYRICS'],\n",
        "          ),\n",
        "        ] * hps.n_samples\n",
        "\n",
        "if resume_state != 'upsampling': \n",
        "  labels = top_prior.labeller.get_batch_labels(metas, 'cuda')\n",
        "  sampling_kwargs = dict(temp=sampling_temperature, fp16=True, max_batch_size=lower_batch_size,\n",
        "                    chunk_size=lower_level_chunk_size)    \n",
        "else:\n",
        "  labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]\n",
        "  sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                        chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=0.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                         chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=sampling_temperature, fp16=True, \n",
        "                         max_batch_size=max_batch_size, chunk_size=chunk_size)]\n",
        "\n",
        "def seconds_to_tokens(sec, sr, prior, chunk_size):\n",
        "  tokens = sec * hps.sr // prior.raw_to_tokens\n",
        "  tokens = ((tokens // chunk_size) + 1) * chunk_size\n",
        "  print(f\"tokens {tokens} prior.n_ctx {prior.n_ctx}\")\n",
        "  assert tokens <= prior.n_ctx, 'The continuation length exceeds 23 seconds!'\n",
        "  #if tokens > prior.n_ctx:\n",
        "  #  tokens = prior.n_ctx\n",
        "  return tokens\n",
        "\n",
        "def get_length():\n",
        "  the_length = 0\n",
        "  level_0_wav = glob.glob(os.path.join(hps.name, 'level_0/*0.wav'))\n",
        "  level_1_wav = glob.glob(os.path.join(hps.name, 'level_1/*0.wav'))\n",
        "  if level_0_wav != []:\n",
        "    print_fancy(\"resuming level_0\")\n",
        "    the_length = librosa.get_duration(filename=level_0_wav[0]) \n",
        "  elif level_1_wav != []:\n",
        "    print_fancy(\"resuming level_1\")\n",
        "    the_length = librosa.get_duration(filename=level_1_wav[0]) \n",
        "  elif resume_state ==  'composing':\n",
        "    the_length = info[\"SONG_LENGTH\"]   \n",
        "  return the_length\n",
        "\n",
        "if resume_state != \"\":   \n",
        "  print_fancy(f'Resuming execution, state: {resume_state}. Rendered length {int(get_length())} sec.')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jqh7Few5tKNG"
      },
      "source": [
        "# **Initial** **Generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxe9j_YKTLKW"
      },
      "source": [
        "This will generate the starting point of your song.\n",
        "\n",
        "If you are returning to an earlier session / branch skip this step. \n",
        "\n",
        "If you are not sure, check the violet text in the previous cells output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOntjnB1tIsH",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Generate the beginning of your song\n",
        "\n",
        "if resume_state == '':\n",
        "  if os.path.isfile(ckpt):\n",
        "    # redo initial generation\n",
        "    #!rm {ckpt}\n",
        "    os.remove(ckpt) \n",
        "    #!rm -r {hps.name}/level_2\n",
        "    os.rmtree(f'{hps.name}/level_2')\n",
        "\n",
        "  assert sample_hps.audio_file is not None\n",
        "  audio_files = sample_hps.audio_file.split(',')\n",
        "  duration = (int(sample_hps.prompt_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  tokens_to_sample = seconds_to_tokens(INITIAL_SONG_LENGTH, hps.sr, top_prior, chunk_size)  \n",
        "\n",
        "  x = load_prompts(audio_files, duration, hps)\n",
        "  zs = top_prior.encode(x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0])\n",
        "  \n",
        "  zs = sample_partial_window(zs, labels, sampling_kwargs, 2, top_prior, tokens_to_sample, hps)\n",
        "  x = vqvae.decode(zs[2:], start_level=2).cpu().numpy()\n",
        "  x = scale_sample(x)\n",
        "  song_length = INITIAL_SONG_LENGTH\n",
        "  print_fancy(f\"Song length: {song_length} seconds. Remaining time: {TOTAL_SONG_LENGTH - song_length}\") \n",
        "  write_audio(0)      \n",
        "  t.save(zs, ckpt)\n",
        "  #!cp /content/clip_*.wav {hps.name}\n",
        "  for i in range(hps.n_samples):\n",
        "    shutil.copy(f'/content/clip_{i}.wav', hps.name)\n",
        "  info[\"SONG_LENGTH\"] = song_length\n",
        "  save_info(f_info)\n",
        "  # initial generation done, we enter into mode\n",
        "  resume_state = \"composing\"\n",
        "  empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfrapAMnAfKO"
      },
      "source": [
        "Once the initial generation has finished, you can listen the  clips.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWTtc2qqfIhb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Open clips\n",
        "if resume_state != \"data\":\n",
        "  audios = []\n",
        "  for i in range(hps.n_samples):\n",
        "    print(f'Clip {i}')\n",
        "    display(Audio(f'clip_{i}.wav'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MPeJYzsEHEN"
      },
      "source": [
        "If you didn't like any of the initial clips, just go back to *Initial generation* and run the first cell again.\n",
        "\n",
        "If there is one that you like, proceed to the next section (\"Add to the composition\").\n",
        "\n",
        "If there are more than one that you like, run the cell below to make a \"new branch\" that you can work with later. The branch saves only what has been added since the last round of generation.\n",
        "\n",
        " Then pick one to extend now and proceed to the next section (\"Add to the composition\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcW00sPH-Ahn",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Make a branch for later use\n",
        "NOTE = 'also-2-4' #@param {type:\"string\"}\n",
        "backup(zs,NOTE)\n",
        "#read_info(hps.name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7CzSiv0MmFP"
      },
      "source": [
        "# **Add** **To** **Composition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Woh54TZcBh18"
      },
      "source": [
        "You have now generated the start of your song. Here you input options for continuing the song. You'll return here to extend the song until you're ready to render the final tune.\n",
        "\n",
        "**run_again**: select if you already ran this cell but weren't happy with any of the results.  Be sure and turn it back off or you will keep generating samples for the same point over and over.\n",
        "\n",
        "**Choice**: the number (0,1,2) of the clip you wish to extend. The clips can be found in the project folder.\n",
        "\n",
        "**Addition length**: How many seconds are you going to add to the song? \n",
        "\n",
        "**Playback start**: How many seconds (if any) do you wish to skip on playback?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnbfgWDXR1bN",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Input song continuation options\n",
        "run_again = False #@param {type:\"boolean\"}\n",
        "CHOICE =  3#@param {type:\"number\"}\n",
        "ADDITION_LENGTH =  4#@param {type:\"number\"}\n",
        "PLAYBACK_SET =  19#@param {type:\"number\"}\n",
        "if \"PLAYBACK_SAVE\" not in globals():\n",
        "  PLAYBACK_START = PLAYBACK_SET\n",
        "  PLAYBACK_SAVE = PLAYBACK_SET\n",
        "elif PLAYBACK_SET != PLAYBACK_SAVE:\n",
        "  PLAYBACK_START = PLAYBACK_SAVE = PLAYBACK_SET\n",
        "else:\n",
        "  if not run_again:\n",
        "    PLAYBACK_START = PLAYBACK_START + ADDITION_LENGTH\n",
        "print(f\"playback start at {PLAYBACK_START} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You can change the temperature before any continuation.  \n",
        "\n",
        "They say 0.96 to 0.99 works best.\n",
        "\n",
        "If you want to calm down the abruptness of change, set a lower temperature.  If you to increase the likelihood of change, raise the temperatures  If you like how things are going with the temperature, just skip the cell."
      ],
      "metadata": {
        "id": "DhsHoW-DPraj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Change the Sampling Temperature If You'd Like\n",
        "sampling_temperature = .97 #@param {type:\"number\"\n",
        "sampling_kwargs = dict(temp=sampling_temperature, fp16=True, max_batch_size=lower_batch_size,\n",
        "                    chunk_size=lower_level_chunk_size)"
      ],
      "metadata": {
        "id": "q1t0E6GuCbMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_XFtVi99CIY",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Continue generating the song\n",
        "empty_cache()\n",
        "\n",
        "\n",
        "if resume_state != \"data\":\n",
        "  if run_again:\n",
        "     if os.path.isfile(b_ckpt) and os.path.isfile(b_info):\n",
        "       #!cp {b_ckpt} {ckpt}\n",
        "       shutil.copy(b_ckpt,ckpt)\n",
        "       #!cp {b_info} {f_info}\n",
        "       shutil.copy(b_info,f_info)\n",
        "     else:\n",
        "       print(\"Failed to run again\")  \n",
        "  else:           \n",
        "    #!cp {ckpt} {b_ckpt}\n",
        "    shutil.copy(ckpt,b_ckpt)\n",
        "    #!cp {f_info} {b_info}\n",
        "    shutil.copy(f_info,b_info)\n",
        "  \n",
        "  info = read_info(f_info)\n",
        "  song_length = info[\"SONG_LENGTH\"]\n",
        "  zs=t.load(ckpt) \n",
        "  \n",
        "  tokens_list = get_tokens_list(zs)\n",
        "  # generate music\n",
        " \n",
        "  zs[2]=zs[2][CHOICE].repeat(hps.n_samples,1)\n",
        "\n",
        "  tokens_to_sample = seconds_to_tokens(ADDITION_LENGTH, hps.sr, top_prior, chunk_size)  \n",
        "  print(f\"tokens to sample : {tokens_to_sample}\")\n",
        "  zs = sample_partial_window(zs, labels, sampling_kwargs, 2, top_prior, tokens_to_sample, hps)\n",
        "  \n",
        "  empty_cache()\n",
        "  x = vqvae.decode(zs[2:], start_level=2).cpu().numpy()\n",
        "  x = scale_sample(x)\n",
        "  #write audio clips\n",
        "  write_audio(PLAYBACK_START)\n",
        "\n",
        "  # write checkpoint\n",
        "  song_length += ADDITION_LENGTH\n",
        "  print_fancy(f\"Song length: {song_length} seconds. Remaining time: {TOTAL_SONG_LENGTH - song_length}\") \n",
        "  t.save(zs, f'{hps.name}/zs-checkpoint.t')\n",
        "  #!cp /content/clip_*.wav \"{hps.name}\"\n",
        "  for i in range(hps.n_samples):\n",
        "    shutil.copy(f'/content/clip_{i}.wav', hps.name)\n",
        "  info[\"SONG_LENGTH\"] = song_length\n",
        "  save_info(f_info)\n",
        "  empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiIefM-wbSSY",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Open clips\n",
        "if resume_state != \"data\":\n",
        "  audios = []\n",
        "  for i in range(hps.n_samples):\n",
        "    print(f'Clip {i}')\n",
        "    display(Audio(f'clip_{i}.wav'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OJT704dvnGv"
      },
      "source": [
        "To keep on extending the song, return to **Add to the composition** , input your choices and run the cells again.\n",
        "\n",
        "If you didn't like any of the clips, check the ***run_again*** checkbox and run the **Continue generating** cell again. (Remember to uncheck it when you're done!)\n",
        "\n",
        "If your song is getting near the full length, or you are happy with it as it is now, proceed to the next section to upsample.\n",
        "\n",
        "If there are more than one that you like, run the cell below to make a \"new branch\" that you can work with later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSI9c_bls6bu",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Make a branch for later use\n",
        "NOTE = '1-3' #@param {type:\"string\"}\n",
        "backup(zs,NOTE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzCrkCZJvUcQ"
      },
      "source": [
        "# **Upsample**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsAJitNdGJBF"
      },
      "source": [
        "It remains for you to choose the clip to be rendered to better quality audio.\n",
        "\n",
        "If on the other hand you would like to render all of them at the same time, leave CHOICE as \"None\" (Be aware that this increases the upsampling time)\n",
        "\n",
        "There are two upsampling levels: level_1 and level_0 (The noisy initial generation is level_2). The less the level number, the better it sounds.\n",
        "\n",
        "When the upsampling is done, the results can be found in new folders called **level_1**, **level_0** inside your project directory. \n",
        "\n",
        "If you are upsampling a branch from previous session, you can also *truncate* the branch, so that it upsamples only that part of the song which is new.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u6Ok7WACibh",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Upsampling settings\n",
        "\n",
        "CHOICE = 2 #@param {type:\"raw\"}\n",
        "truncate = False #@param {type:\"boolean\"}\n",
        "zs=t.load(ckpt) \n",
        "info = read_info(f_info)\n",
        "tokens_list = info[\"TOKENS\"]\n",
        "if truncate:\n",
        "  zs = truncate_zs(zs)\n",
        "if CHOICE is not None:   \n",
        "  hps.n_samples = 1\n",
        "  CHOICE = int(CHOICE)\n",
        "  #prune all but the choice \n",
        "  nzs = []\n",
        "  for i in range(len(zs)):\n",
        "    zs_lvl = t.zeros(1, zs[i].shape[1],dtype=t.int64)\n",
        "    zs_lvl[0] = zs[i][CHOICE]\n",
        "    nzs.append(zs_lvl)\n",
        "  \n",
        "  metas = [dict(artist = info['ARTIST'],\n",
        "          genre = info['GENRE'],\n",
        "          total_length = hps.sample_length,\n",
        "          offset = 0,\n",
        "          lyrics = info['LYRICS'],\n",
        "          ),]   \n",
        "else:\n",
        "  nzs = zs    \n",
        "\n",
        "t.save(nzs,f'{hps.name}/zs-checkpoint-final.t')\n",
        "# values for speed upsampling \n",
        "\n",
        "hps.hop_fraction = [1, 1, .125] \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k676vNaV3PHX",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Upsample your favorite clip \n",
        "\n",
        "if (resume_state != \"upsampling\"):\n",
        "  zs = t.load(f'{hps.name}/zs-checkpoint-final.t')\n",
        "  assert zs[2].shape[1]>=2048, f'Please first generate at least 2048 tokens at the top level, currently you have {zs[2].shape[1]}'\n",
        "  hps.sample_length = zs[2].shape[1]*top_prior.raw_to_tokens \n",
        "  del top_prior\n",
        "  empty_cache()\n",
        "  top_prior=None\n",
        "  upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n",
        "  sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=16, chunk_size=32),\n",
        "                    dict(temp=0.99, fp16=True, max_batch_size=16, chunk_size=32),\n",
        "                    None]\n",
        "  if type(labels)==dict:\n",
        "    labels = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers] + [labels] \n",
        "  \n",
        "\n",
        "else: #upsampling from level 1\n",
        "  assert sample_hps.codes_file is not None\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  assert zs[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  del data\n",
        "  del top_prior\n",
        "  empty_cache()\n",
        "  top_prior=None\n",
        "  upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n",
        "  labels[:2] = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers]\n",
        "  \n",
        "zs = upsample(zs, labels, sampling_kwargs, [*upsamplers, top_prior], hps)\n",
        "del upsamplers\n",
        "empty_cache()\n",
        "print(\"Done.\")\n",
        "\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "private_outputs": true,
      "gpuClass": "premium",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}